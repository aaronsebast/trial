<!doctype html>
model: 'gpt-4o-mini', // substitute with a model available to you
messages: [
{role:'system',content: system + '\nAnnouncements:\n' + annText},
{role:'user',content: question}
],
max_tokens: 400,
temperature: 0.2
});
const answer = response.data.choices[0].message.content.trim();
res.json({answer});
}catch(err){ console.error(err); res.status(500).json({error:err.message||String(err)}); }
});


// Summarize & classify
app.post('/api/summarize', async (req,res)=>{
try{
const {title,content,category} = req.body;
const prompt = `Summarize the following announcement into a 1-line headline and 3 concise bullet points. Also suggest a priority: High, Medium or Low. Return JSON with keys: summary, bullets (array), priority.`;
const response = await client.createChatCompletion({ model:'gpt-4o-mini', messages:[{role:'system',content:prompt},{role:'user',content:`Title: ${title}\nCategory: ${category}\nContent: ${content}`}], max_tokens:300, temperature:0.0 });
const answer = response.data.choices[0].message.content;
// Try to extract JSON â€” if model returns plain text, wrap it
let parsed = {summary: null, bullets: [], priority: 'Medium'};
try{ parsed = JSON.parse(answer) }catch(e){
// fallback: simple parsing
parsed.summary = answer.split('\n')[0]; parsed.bullets = []; parsed.priority = 'Medium';
}
res.json(parsed);
}catch(err){ console.error(err); res.status(500).json({error:err.message}); }
});


// Embedding-based indexing & search (very simple in-memory for demo)
let embeddingIndex = []; // each: {id, title, content, category, embedding}


app.post('/api/emb_search', async (req,res)=>{
try{
const {op, announcement, query, announcements} = req.body;
if(op === 'index' && announcement){
// compute embedding
const embedResp = await client.createEmbedding({ model:'text-embedding-3-large', input: announcement.title + '\n' + announcement.content });
const emb = embedResp.data.data[0].embedding;
embeddingIndex.push({id:announcement.id, title:announcement.title, content:announcement.content, category:announcement.category, embedding:emb});
return res.json({ok:true});
}
if(op === 'search'){
// Build embedding for query
const q = query || '';
const qEmbResp = await client.createEmbedding({ model:'text-embedding-3-large', input: q });
const qEmb = qEmbResp.data.data[0].embedding;
// simple cosine similarity
function dot(a,b){ return a.reduce((s,v,i)=>s+v*b[i],0) }
function norm(a){ return Math.sqrt(a.reduce((s,v)=>s+v*v,0)) }
const qn = norm(qEmb);
const scored = (announcements || embeddingIndex).map(a=>{
const emb = a.embedding || (embeddingIndex.find(x=>x.id===a.id)?.embedding);
if(!emb) return {...a,score:0};
const score = dot(qEmb,emb) / (qn * norm(emb));
return {...a, score};
}).sort((a,b)=>b.score - a.score).slice(0,6);


// create short snippet for each
const results = scored.map(s=>({id:s.id,title:s.title,category:s.category,content:s.content,score:s.score, snippet: s.content.slice(0,220)}));
return res.json({results});
}
res.json({error:'invalid op'});
}catch(err){ console.error(err); res.status(500).json({error:err.message}); }
});


// Translation endpoint
app.post('/api/translate', async (req,res)=>{
try{
const {text, to} = req.body;
const prompt = `Translate the following text into ${to}. Keep it natural and concise.`;
const response = await client.createChatCompletion({ model:'gpt-4o-mini', messages:[{role:'system',content:prompt},{role:'user',content:text}], max_tokens:400 });
res.json({translation: response.data.choices[0].message.content.trim()});
}catch(err){ console.error(err); res.status(500).json({error:err.message}); }
});


const PORT = process.env.PORT || 3000; app.listen(PORT, ()=>console.log('Server running on', PORT));
</script>


</body>
</html>
